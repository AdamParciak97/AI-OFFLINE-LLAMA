# AI-OFFLINE-LLAMA

## Download model LlaMA 3-8B
```bash
https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/blob/main/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
```

## Download docker image on docker desktop
```bash
docker pull ghcr.io/ggerganov/llama.cpp:server
docker save ghcr.io/ggerganov/llama.cpp:server -o C:\llama-server.tar
```

